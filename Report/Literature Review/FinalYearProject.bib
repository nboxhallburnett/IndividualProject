Automatically generated by Mendeley Desktop 1.15.2
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@inproceedings{Lindley2005,
abstract = {Trans-reality games are games that take advantage of pervasive, mobile, ubiquitous, location-based and mixed reality technical infrastructures to create game spaces that can include physical reality together with one or more virtual realities. Creating these games requires basic design decisions about the relationships between the large scale game spaces involved. In particular, the different game spaces can be related by general 3D coordinate system transforms, together with decisions regarding isomorphism at different levels of spatial scale. The result is a large space of possibilities for trans-reality game space design supporting very different forms of game mechanics.},
address = {New York, New York, USA},
author = {Lindley, Craig A.},
booktitle = {Proceedings of the 2005 ACM SIGCHI International Conference on Advances in computer entertainment technology - ACE '05},
doi = {10.1145/1178477.1178569},
file = {:C\:/Users/Nathan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Lindley - 2005 - Game space design foundations for trans-reality games.pdf:pdf},
isbn = {1595931104},
keywords = {game space design,mixed reality games,trans-reality games},
month = {jun},
pages = {397--404},
publisher = {ACM Press},
title = {{Game space design foundations for trans-reality games}},
url = {http://dl.acm.org/citation.cfm?id=1178477.1178569},
year = {2005}
}
@article{Diemer2015,
abstract = {Virtual reality (VR) has made its way into mainstream psychological research in the last two decades. This technology, with its unique ability to simulate complex, real situations and contexts, offers researchers unprecedented opportunities to investigate human behavior in well controlled designs in the laboratory. One important application of VR is the investigation of pathological processes in mental disorders, especially anxiety disorders. Research on the processes underlying threat perception, fear, and exposure therapy has shed light on more general aspects of the relation between perception and emotion. Being by its nature virtual, i.e., simulation of reality, VR strongly relies on the adequate selection of specific perceptual cues to activate emotions. Emotional experiences in turn are related to presence, another important concept in VR, which describes the user's sense of being in a VR environment. This paper summarizes current research into perception of fear cues, emotion, and presence, aiming at the identification of the most relevant aspects of emotional experience in VR and their mutual relations. A special focus lies on a series of recent experiments designed to test the relative contribution of perception and conceptual information on fear in VR. This strand of research capitalizes on the dissociation between perception (bottom-up input) and conceptual information (top-down input) that is possible in VR. Further, we review the factors that have so far been recognized to influence presence, with emotions (e.g., fear) being the most relevant in the context of clinical psychology. Recent research has highlighted the mutual influence of presence and fear in VR, but has also traced the limits of our current understanding of this relationship. In this paper, the crucial role of perception on eliciting emotional reactions is highlighted, and the role of arousal as a basic dimension of emotional experience is discussed. An interoceptive attribution model of presence is suggested as a first step toward an integrative framework for emotion research in VR. Gaps in the current literature and future directions are outlined.},
author = {Diemer, Julia and Alpers, Georg W and Peperkorn, Henrik M and Shiban, Youssef and M{\"{u}}hlberger, Andreas},
doi = {10.3389/fpsyg.2015.00026},
file = {:C\:/Users/Nathan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Diemer et al. - 2015 - The impact of perception and presence on emotional reactions a review of research in virtual reality.pdf:pdf},
issn = {1664-1078},
journal = {Frontiers in psychology},
keywords = {Psychology,VR},
mendeley-tags = {Psychology,VR},
month = {jan},
pages = {26},
pmid = {25688218},
title = {{The impact of perception and presence on emotional reactions: a review of research in virtual reality.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=4311610&tool=pmcentrez&rendertype=abstract},
volume = {6},
year = {2015}
}
@article{Ruddle2013,
abstract = {This article provides longitudinal data for when participants learned to travel with a walking metaphor through virtual reality (VR) worlds, using interfaces that ranged from joystick-only, to linear and omnidirectional treadmills, and actual walking in VR. Three metrics were used: travel time, collisions (a measure of accuracy), and the speed profile. The time that participants required to reach asymptotic performance for traveling, and what that asymptote was, varied considerably between interfaces. In particular, when a world had tight turns (0.75 m corridors), participants who walked were more proficient than those who used a joystick to locomote and turned either physically or with a joystick, even after 10 minutes of training. The speed profile showed that this was caused by participants spending a notable percentage of the time stationary, irrespective of whether or not they frequently played computer games. The study shows how speed profiles can be used to help evaluate participants' proficiency with travel interfaces, highlights the need for training to be structured to addresses specific weaknesses in proficiency (e.g., start-stop movement), and for studies to measure and report that proficiency.},
author = {Ruddle, Roy A. and Volkova, Ekaterina and B{\"{u}}lthoff, Heinrich H.},
doi = {10.1145/2465780.2465785},
file = {:C\:/Users/Nathan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Ruddle, Volkova, B{\"{u}}lthoff - 2013 - Learning to walk in virtual reality.pdf:pdf},
issn = {15443558},
journal = {ACM Transactions on Applied Perception},
keywords = {Virtual reality interfaces,metrics,navigation,travel},
month = {may},
number = {2},
pages = {1--17},
publisher = {ACM},
title = {{Learning to walk in virtual reality}},
url = {http://dl.acm.org/citation.cfm?id=2465780.2465785},
volume = {10},
year = {2013}
}
@article{Kokkinara:2015:EVC:2837040.2818998,
abstract = {We easily adapt to changes in the environment that involve cross-sensory discrepancies (e.g., between vision and proprioception). Adaptation can lead to changes in motor commands so that the experienced sensory consequences are appropriate for the new environment (e.g., we program a movement differently while wearing prisms that shift our visual space). In addition to these motor changes, perceptual judgments of space can also be altered (e.g., how far can I reach with my arm?). However, in previous studies that assessed perceptual judgments of space after visuomotor adaptation, the manipulation was always a planar spatial shift, whereas changes in body perception could not directly be assessed. In this study, we investigated the effects of velocity-dependent (spatiotemporal) and spatial scaling distortions of arm movements on space and body perception, taking advantage of immersive virtual reality. Exploiting the perceptual illusion of embodiment in an entire virtual body, we endowed subjects with new spatiotemporal or spatial 3D mappings between motor commands and their sensory consequences. The results imply that spatiotemporal manipulation of 2 and 4 times faster can significantly change participants’ proprioceptive judgments of a virtual object’s size without affecting the perceived body ownership, although it did affect the agency of the movements. Equivalent spatial manipulations of 11 and 22 degrees of angular offset also had a significant effect on the perceived virtual object’s size; however, the mismatched information did not affect either the sense of body ownership or agency. We conclude that adaptation to spatial and spatiotemporal distortion can similarly change our perception of space, although spatiotemporal distortions can more easily be detected.},
address = {New York, NY, USA},
author = {Kokkinara, Elena and Slater, Mel and L{\'{o}}pez-Moliner, Joan},
doi = {10.1145/2818998},
file = {:C\:/Users/Nathan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Kokkinara, Slater, L{\'{o}}pez-Moliner - 2015 - The Effects of Visuomotor Calibration to the Perceived Space and Body, Through Embodiment in I.pdf:pdf},
issn = {1544-3558},
journal = {ACM Trans. Appl. Percept.},
keywords = {Body ownership,sensorimotor adaptation,space perception,spatiotemporal distortions,virtual reality},
month = {oct},
number = {1},
pages = {3:1----3:22},
publisher = {ACM},
title = {{The Effects of Visuomotor Calibration to the Perceived Space and Body, Through Embodiment in Immersive Virtual Reality}},
url = {http://doi.acm.org/10.1145/2818998},
volume = {13},
year = {2015}
}
@inproceedings{Wright2009,
abstract = {The level of immersion that is induced in an individual can be measured by subjective report, but VE immersion can also affect automatic sensorimotor processes which function below perceptual thresholds. Such sub-threshold effects on central nervous system processing are important to understand for the purposes of shaping VE rehabilitation. This study investigates the effect of dynamic immersive VE on self-motion perception and automatic upper extremity motor response. Subjects viewed either horizontal or vertical sinusoidal linear translation plusmn1 m at 0.25 Hz via a head-mounted display (HMD) while sitting in a stationary motion apparatus. Subjects performed a perceptuomotor task of aligning a handheld object to perceived vertical using their unconstrained arm (i.e. free to move in 6 DOF). Two objects were tested, a joystick and a full glass of water, in counter-balanced order. Results show the majority of subjects perceive self-motion that spatially and temporally agrees with the visually depicted VE motion. This occurs despite the absence of sinusoidally varying changes to gravitoinertial forces, since subjects are not exposed to actual physical motion. Despite only being instructed to orient the handheld object, handheld object kinematics also show automatic motor responses involving object translation. These manual motor responses were dependent on the direction and phase of the visual motion depicted in the VE. Specifically, vertical visual motion induced vertical translation and pitch tilt of the handheld object, while horizontal visual motion induced horizontal translation and roll tilt of the object. Motor responses were significantly greater in subjects who reported compelling self-motion perception. These findings suggest that a representation of net gravitoinertial forces can be derived from the high-fidelity, pictorial and dynamic depth cues visually presented in a VE. Automatic upper extremity manual responses which are controlled by descending cent- ral systems and tracts dissociable from lower extremities can be affected by immersion in a VE much like automatic postural behavior has been shown to be. This new evidence supports current efforts to conduct upper extremity rehabilitation in the relative safe and controllable experimental environments that VE technology affords.},
author = {Wright, W. Geoffrey and Schneider, Erich},
booktitle = {2009 Virtual Rehabilitation International Conference},
doi = {10.1109/ICVR.2009.5174226},
isbn = {978-1-4244-4188-4},
keywords = {Automatic control,Central nervous system,Displays,Extremities,Force control,Glass,Immersion,Kinematics,Manual control,Motor drives,Presence,Sensorimotor integration,Testing,Upper extremity,VE immersion,VE rehabilitation,Vection,Virtual reality,automatic motor responses,automatic sensorimotor processes,automatic upper extremity motor response,biomechanics,central nervous system processing,dynamic depth cues,dynamic immersive VE,gravitoinertial forces,handheld object kinematics,head-mounted display,helmet mounted displays,manual motor control,manual motor responses,net gravitoinertial forces,object translation,patient rehabilitation,perceptuomotor task,self-motion perception,sinusoidal linear translation,stationary motion apparatus,sub-threshold effects,virtual reality,virtual self-motion,visual perception,visually depicted VE motion},
month = {jun},
pages = {166--172},
publisher = {IEEE},
shorttitle = {Virtual Rehabilitation International Conference, 2},
title = {{Manual motor control during “virtual” self-motion: Implications for VR rehabilitation}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5174226},
year = {2009}
}
@article{Cheng2014,
abstract = {With the rapid development of the VR market, virtual experience has increasingly been the object of study in recent years. A growing number of studies have reported the positive effect that virtual experience can have on a user’s mood and loyalty. However, few studies have investigated the influence of the mechanism of virtual experience on users’ mood and loyalty. To compensate for this research gap, this study aims to evaluate consumers’ virtual experience by examining the flow state in a virtual environment. A total of 368 valid questionnaires were collected, and a structural equation modeling approach was employed in the data analysis. The study reveals that forming flow involves many factors: the intrinsic characteristics of the mediated environment, the consumer’s assumptions and perceptions prior to entering the flow state, the stage at which the customer enters the flow state, and the consequences of the flow experience.},
author = {Cheng, Li-Keng and Chieng, Ming-Hua and Chieng, Wei-Hua},
doi = {10.1007/s10055-014-0244-2},
file = {:C\:/Users/Nathan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Cheng, Chieng, Chieng - 2014 - Measuring virtual experience in a three-dimensional virtual reality interactive simulator environment a s.pdf:pdf},
issn = {1359-4338},
journal = {Virtual Reality},
keywords = {Flow,Interactivity,Telepresence,Virtual experience,Vividness},
month = {jan},
number = {3},
pages = {173--188},
title = {{Measuring virtual experience in a three-dimensional virtual reality interactive simulator environment: a structural equation modeling approach}},
url = {http://link.springer.com/10.1007/s10055-014-0244-2},
volume = {18},
year = {2014}
}
@misc{Antichamber2013,
author = {Bruce, Alexander},
publisher = {Demruth},
title = {{Antichamber. [Video Game]}},
type = {Video Game},
year = {2013}
}
@article{Maric2014,
author = {Mari{\'{c}}, Filip and Petrovi{\'{c}}, Danijela},
doi = {10.1007/s10472-014-9436-4},
file = {:C\:/Users/Nathan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Mari{\'{c}}, Petrovi{\'{c}} - 2014 - Formalizing complex plane geometry(2).pdf:pdf},
issn = {1012-2443},
journal = {Annals of Mathematics and Artificial Intelligence},
month = {nov},
number = {3-4},
pages = {271--308},
title = {{Formalizing complex plane geometry}},
url = {http://link.springer.com/10.1007/s10472-014-9436-4},
volume = {74},
year = {2014}
}
@inproceedings{Wright2013,
abstract = {Adaptation of sensorimotor processes has been studied for over a century. However, rigorous experimental approaches require controlling as many variables as possible to study the phenomenon, which limits generalizability. Conversely testing adaptation in an unconstrained ecologically valid situation makes it difficult to identify what parameters affect this process. This study utilizes virtual environments (VE) to create complex, but controlled environments to test visual, vestibular, and sensorimotor adaptation of whole-body posture. Findings show automatic postural processes can be adapted to unusual and discordant sensory environments, suggesting its lability would be advantageous when employing the kind of sensorimotor rehabilitation therapy VE affords.},
author = {Wright, W. Geoffrey},
booktitle = {2013 International Conference on Virtual Rehabilitation (ICVR)},
doi = {10.1109/ICVR.2013.6662095},
isbn = {978-1-4799-0774-8},
keywords = {Eye protection,Optical sensors,Sea surface,Trajectory,Virtual environments,Visualization,control engineering computing,cross-axis adaptation,ecology,insert,patient rehabilitation,patient treatment,postural control,posture,sensorimotor adaptation,sensorimotor process,sensorimotor rehabilitation therapy,style,styling,unconstrained ecology,virtual environments,virtual reality},
month = {aug},
pages = {289--294},
publisher = {IEEE},
shorttitle = {Virtual Rehabilitation (ICVR), 2013 International },
title = {{Using virtual reality to induce cross-axis adaptation of postural control: Implications for rehabilitation}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6662095},
year = {2013}
}
@article{smith2015,
abstract = {Immersive virtual environment (IVE) technology offers a wide range of potential benefits to research focused on understanding how individuals perceive and respond to built and natural environments. In an effort to broaden awareness and use of IVE technology in perception, preference and behavior research, this review paper describes how IVE technology can be used to complement more traditional methods commonly applied in public health research. The paper also describes a relatively simple workflow for creating and displaying 360° virtual environments of built and natural settings and presents two freely-available and customizable applications that scientists from a variety of disciplines, including public health, can use to advance their research into human preferences, perceptions and behaviors related to built and natural settings.},
author = {Smith, Jordan W},
doi = {10.3390/ijerph120911486},
file = {:C\:/Users/Nathan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Smith - 2015 - Immersive Virtual Environment Technology to Supplement Environmental Perception, Preference and Behavior Research A Revie.pdf:pdf},
issn = {1660-4601},
journal = {International Journal of Environmental Research and Public Health},
keywords = {ecological validity,experimental control,experimental research,virtual reality},
number = {9},
pages = {11486},
title = {{Immersive Virtual Environment Technology to Supplement Environmental Perception, Preference and Behavior Research: A Review with Applications}},
url = {http://www.mdpi.com/1660-4601/12/9/11486},
volume = {12},
year = {2015}
}
@inproceedings{Elliott2015,
abstract = {Software engineers primarily interact with source code using a keyboard and mouse, and typically view software on a small number of 2D monitors. This interaction paradigm does not take advantage of many affordances of natural human movement and perception. Virtual reality (VR) can use these affordances more fully than existing developer environments to enable new creative opportunities and potentially result in higher productivity, lower learning curves, and increased user satisfaction. This paper describes the affordances offered by VR, demonstrates the benefits of VR and software engineering in prototypes for live coding and code review, and discusses future work, open questions, and the challenges of VR.},
author = {Elliott, Anthony and Peiris, Brian and Parnin, Chris},
booktitle = {2015 IEEE/ACM 37th IEEE International Conference on Software Engineering},
doi = {10.1109/ICSE.2015.191},
file = {:C\:/Users/Nathan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Elliott, Peiris, Parnin - 2015 - Virtual Reality in Software Engineering Affordances, Applications, and Challenges.pdf:pdf},
isbn = {978-1-4799-1934-5},
keywords = {Cognition,Encoding,Keyboards,Navigation,Software,Software engineering,Three-dimensional displays,VR,code review,live coding,software engineering,software reviews,source code,source code (software),virtual reality},
month = {may},
pages = {547--550},
publisher = {IEEE},
shorttitle = {Software Engineering (ICSE), 2015 IEEE/ACM 37th IE},
title = {{Virtual Reality in Software Engineering: Affordances, Applications, and Challenges}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=7203009},
volume = {2},
year = {2015}
}
@article{Chen2014,
abstract = {ObjectiveIn this study, we compared how users locate physical and equivalent three-dimensional images of virtual objects in a cave automatic virtual environment (CAVE) using the hand to examine how human performance (accuracy, time, and approach) is affected by object size, location, and distance. BackgroundVirtual reality (VR) offers the promise to flexibly simulate arbitrary environments for studying human performance. Previously, VR researchers primarily considered differences between virtual and physical distance estimation rather than reaching for close-up objects. MethodFourteen participants completed manual targeting tasks that involved reaching for corners on equivalent physical and virtual boxes of three different sizes. Predicted errors were calculated from a geometric model based on user interpupillary distance, eye location, distance from the eyes to the projector screen, and object. ResultsUsers were 1.64 times less accurate (p < .001) and spent 1.49 times more time (p = .01) targeting virtual versus physical box corners using the hands. Predicted virtual targeting errors were on average 1.53 times (p < .05) greater than the observed errors for farther virtual targets but not significantly different for close-up virtual targets. ConclusionTarget size, location, and distance, in addition to binocular disparity, affected virtual object targeting inaccuracy. Observed virtual box inaccuracy was less than predicted for farther locations, suggesting possible influence of cues other than binocular vision. ApplicationHuman physical interaction with objects in VR for simulation, training, and prototyping involving reaching and manually handling virtual objects in a CAVE are more accurate than predicted when locating farther objects.},
author = {Chen, K. B. and Kimmel, R. a. and Bartholomew, a. and Ponto, K. and Gleicher, M. L. and Radwin, R. G.},
doi = {10.1177/0018720814523067},
file = {:C\:/Users/Nathan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen et al. - 2014 - Manually Locating Physical and Virtual Reality Objects.pdf:pdf},
issn = {0018-7208},
journal = {Human Factors: The Journal of the Human Factors and Ergonomics Society},
keywords = {physical interface,simula-,virtual reality},
month = {feb},
number = {6},
pages = {1163--1176},
title = {{Manually Locating Physical and Virtual Reality Objects}},
url = {http://hfs.sagepub.com/content/56/6/1163?etoc},
volume = {56},
year = {2014}
}
@inproceedings{Cruz-Neira1993,
address = {New York, New York, USA},
author = {Cruz-Neira, Carolina and Sandin, Daniel J. and DeFanti, Thomas A.},
booktitle = {Proceedings of the 20th annual conference on Computer graphics and interactive techniques - SIGGRAPH '93},
doi = {10.1145/166117.166134},
file = {:C\:/Users/Nathan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Cruz-Neira, Sandin, DeFanti - 1993 - Surround-screen projection-based virtual reality.pdf:pdf},
isbn = {0897916018},
keywords = {head-tracking,projection paradigms,real-time manipulation,stereoscopic display,virtual reality},
month = {sep},
pages = {135--142},
publisher = {ACM Press},
title = {{Surround-screen projection-based virtual reality}},
url = {http://dl.acm.org/citation.cfm?id=166117.166134},
year = {1993}
}
@article{Regia-Corte2012,
abstract = {We evaluated the perception of affordances in virtual environments (VE). In our work, we considered the affordances for standing on a virtual slanted surface. Participants were asked to judge whether a virtual slanted surface supported upright stance. The objective was to evaluate whether this perception was possible in virtual reality (VR) and comparable to previous works conducted in real environments. We found that the perception of affordances for standing on a slanted surface in virtual reality is possible and comparable (with an underestimation) to previous studies conducted in real environments. We also found that participants were able to extract and to use virtual information about friction in order to judge whether a slanted surface supported an upright stance. Finally, results revealed that the person’s position on the slanted surface is involved in the perception of affordances for standing on virtual grounds. Taken together, our results show quantitatively that the perception of affordances can be effective in virtual environments and influenced by both environmental and person properties. Such a perceptual evaluation of affordances in VR could guide VE designers to improve their designs and to better understand the effect of these designs on VE users.},
author = {Regia-Corte, Tony and Marchal, Maud and Cirio, Gabriel and L{\'{e}}cuyer, Anatole},
doi = {10.1007/s10055-012-0216-3},
file = {:C\:/Users/Nathan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Regia-Corte et al. - 2012 - Perceiving affordances in virtual reality influence of person and environmental properties in perception of.pdf:pdf},
issn = {1359-4338},
journal = {Virtual Reality},
month = {oct},
number = {1},
pages = {17--28},
title = {{Perceiving affordances in virtual reality: influence of person and environmental properties in perception of standing on virtual grounds}},
url = {http://link.springer.com/10.1007/s10055-012-0216-3},
volume = {17},
year = {2012}
}
@article{Turner2009,
author = {Turner, Henry S. and Saiber, Arielle},
file = {:C\:/Users/Nathan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Turner, Saiber - 2009 - Mathematics and the Imagination A Brief Introduction.pdf:pdf},
journal = {Configurations (Baltimore, Md.)},
number = {1},
pages = {1},
title = {{Mathematics and the Imagination: A Brief Introduction}},
volume = {17},
year = {2009}
}
@article{Wright2006,
abstract = {To investigate how visual and vestibular cues are integrated for the perception of gravity during passive self-motion, we measured the ability to maintain a handheld object vertical relative to gravity without visual feedback during sinusoidal roll-tilt stimulation. Visual input, either concordant or discordant with actual dynamic roll-tilt, was delivered by a head-mounted display showing the laboratory. The four visual conditions were darkness, visual-vestibular concordance, stationary visual scene, and a visual scene 180 degrees phase-shifted relative to actual tilt. Tilt-indication performance using a solid, cylindrical joystick was better in the presence of concordant visual input relative to the other visual conditions. In addition, we compared performance when indicating the vertical by the joystick or a full glass of water. Subjects indicated the direction of gravity significantly better when holding the full glass of water than the joystick. Matching the inertial characteristics, including fluid properties, of the handheld object to the glass of water did not improve performance. There was no effect of visual input on tilt performance when using the glass of water to indicate gravitational vertical. The gain of object tilt motion did not change with roll-tilt amplitude and frequency (+/-7.5 degrees at 0.25 Hz, +/-10 degrees at 0.16 Hz, and +/-20 degrees at 0.08 Hz), however, the phase of object tilt relative to subject tilt showed significant phase-leads at the highest frequency tested (0.25 Hz). Comparison of the object and visual effects observed suggest that the task-dependent behavior change may be due to an attentional shift and/or shift in strategy.},
author = {Wright, W G and Glasauer, S},
doi = {10.1007/s00221-006-0347-4},
issn = {0014-4819},
journal = {Experimental brain research},
keywords = {Attention,Attention: physiology,Cues,Feedback,Feedback: physiology,Gravity Sensing,Gravity Sensing: physiology,Humans,Judgment,Judgment: physiology,Neuropsychological Tests,Orientation,Orientation: physiology,Photic Stimulation,Physical Stimulation,Postural Balance,Postural Balance: physiology,Proprioception,Proprioception: physiology,Sensory Deprivation,Sensory Deprivation: physiology,Space Perception,Space Perception: physiology,Tilt-Table Test,Touch,Touch: physiology,User-Computer Interface,Vestibule, Labyrinth,Vestibule, Labyrinth: physiology},
month = {jul},
number = {3},
pages = {310--21},
pmid = {16463151},
title = {{Subjective somatosensory vertical during dynamic tilt is dependent on task, inertial condition, and multisensory concordance.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16463151},
volume = {172},
year = {2006}
}
@article{Wright2014,
abstract = {Technological advances that involve human sensorimotor processes can have both intended and unintended effects on the central nervous system (CNS). This mini review focuses on the use of virtual environments (VE) to augment brain functions by enhancing perception, eliciting automatic motor behavior, and inducing sensorimotor adaptation. VE technology is becoming increasingly prevalent in medical rehabilitation, training simulators, gaming, and entertainment. Although these VE applications have often been shown to optimize outcomes, whether it be to speed recovery, reduce training time, or enhance immersion and enjoyment, there are inherent drawbacks to environments that can potentially change sensorimotor calibration. Across numerous VE studies over the years, we have investigated the effects of combining visual and physical motion on perception, motor control, and adaptation. Recent results from our research involving exposure to dynamic passive motion within a visually-depicted VE reveal that short-term exposure to augmented sensorimotor discordance can result in systematic aftereffects that last beyond the exposure period. Whether these adaptations are advantageous or not, remains to be seen. Benefits as well as risks of using VE-driven sensorimotor stimulation to enhance brain processes will be discussed.},
author = {Wright, W Geoffrey},
doi = {10.3389/fnsys.2014.00056},
file = {:C\:/Users/Nathan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Wright - 2014 - Using virtual reality to augment perception, enhance sensorimotor adaptation, and change our minds.pdf:pdf},
issn = {1662-5137},
journal = {Frontiers in systems neuroscience},
keywords = {Neuroscience,Perception,VR},
mendeley-tags = {Neuroscience,Perception,VR},
month = {jan},
pages = {56},
pmid = {24782724},
title = {{Using virtual reality to augment perception, enhance sensorimotor adaptation, and change our minds.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3986528&tool=pmcentrez&rendertype=abstract},
volume = {8},
year = {2014}
}
@inproceedings{Wright2011,
abstract = {Sensorimotor coordination relies on fine calibration of the interaction among visual, vestibular, and somatosensory input. Our goal was to investigate how the spatiotemporal properties of passive inertial motion and visual input affect head stabilization. Healthy young adults (n=12) wore a head-mounted display during A/P sinusoidal horizontal translations of the whole body. Visual conditions (VIS) displayed forward (EO), sideways (SW), or backward (BW) visual motion relative to the head, plus an eyes-closed conditions (EC) which were combined with 4 inertial conditions to comprise 16 conditions in total. In SW either near or far DEPTH of field with 180° phase shift was displayed. Subjects were secured in a seat with head free to move. Frequency and amplitude of sinusoidal input included overlapping max acceleration (amax) or max velocity (vmax). Amplitude and phase of angular velocity was collected with a 3-axis gyro. A main effect of inertial condition on amplitude for all axes of head motion (p&#60;.0000) and a shift (p&#60;.0000) from phase lead to lag of head pitch with increasing freq (121°, 127°, 83°, −32°) were found. A main effect of VIS on head pitch (p&#60;0.01) was due to the absence of vision (EC). An interaction effect between inertial and VIS conditions on head yaw occurred with SW (p&#60;0.05). In SW, a significant interaction of depth of field and inertia on amplitude (p&#60;0.001) and phase (p&#60;0.05) of head yaw occurred, especially during high vmax conditions. Thus, visual flow can organize lateral cervical responses despite being discordant with inertial input.},
author = {Wright, W. Geoffrey and Agah, Mobin and Darvish, Kurosh and Keshner, Emily A.},
booktitle = {2011 International Conference on Virtual Rehabilitation},
doi = {10.1109/ICVR.2011.5971869},
isbn = {978-1-61284-475-6},
keywords = {Acceleration,Angular velocity,Calibration,Spatiotemporal phenomena,Virtual environments,Visual effects,Visualization},
month = {jun},
pages = {1--4},
publisher = {IEEE},
shorttitle = {Virtual Rehabilitation (ICVR), 2011 International },
title = {{Head stabilization shows multisensory dependence on spatiotemporal characteristics of visual and inertial passive stimulation}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5971869},
year = {2011}
}
@misc{Portal22011,
author = {{Valve Corporation}},
publisher = {Valve Corporation},
title = {{Portal 2. [Video Game]}},
type = {Video Game},
year = {2011}
}
@article{Turchet2015,
abstract = {This paper describes a framework for designing systems for real locomotion in virtual environments (VEs) in order to achieve an intense sense of presence. The main outcome of the present research is a list of design features that the virtual reality technology should have in order to achieve such a goal. To identify these features, an approach based on the combination of two design strategies was followed. The first was based on the theory of affordances and was utilized to design a generic VE in which the affordances of the corresponding real environment could be evoked. The second was the experiential design applied to VEs and was utilized to create an experience of locomotion corresponding to that achievable in a real environment. These design strategies were chosen because of their potential to enhance the sense of presence. The proposed list of features can be utilized as an instrument that allows VE designers to evaluate the maturity of their systems and to pinpoint directions for future developments. A survey analysis was performed using the proposed framework, which involved three case studies to determine how many features of the proposed framework were present and their status. The result of such analysis represented a measure of the completeness of the systems design, of the affordances provided to the user, and a prediction of the sense of presence.},
author = {Turchet, Luca},
doi = {10.1007/s10055-015-0267-3},
file = {:C\:/Users/Nathan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Turchet - 2015 - Designing presence for real locomotion in immersive virtual environments an affordance-based experiential approach.pdf:pdf},
issn = {1359-4338},
journal = {Virtual Reality},
month = {nov},
number = {3-4},
pages = {277--290},
title = {{Designing presence for real locomotion in immersive virtual environments: an affordance-based experiential approach}},
url = {http://link.springer.com/10.1007/s10055-015-0267-3},
volume = {19},
year = {2015}
}
@article{Slater2014,
abstract = {Cognitive neuroscientists have discovered through various experiments that our body representation is surprisingly flexible. Multisensory body illusions work well in immersive virtual reality, and recent findings suggest that they offer both a powerful tool for neuroscience and a new path for future exploration. Because virtual reality is entirely programmed, the form or type of virtual body can be quite different from the participant's actual body, which can impact perception, attitudes, and behavior. A dramatic example of this is when adults inhabiting a virtual child's body overestimate the size of objects and demonstrate implicit attitude and behavioral changes that seem more child-like, but in an adult body the same size as that of a child, they do not exhibit such changes. Here we review the emerging field of body representation and its implications for a new, powerful virtual reality paradigm.},
author = {Slater, Mel and Sanchez-Vives, Maria V.},
doi = {10.1109/MC.2014.198},
file = {:C\:/Users/Nathan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Slater, Sanchez-Vives - 2014 - Transcending the Self in Immersive Virtual Reality.pdf:pdf},
issn = {0018-9162},
journal = {Computer},
keywords = {Avatars,Head,Mirrors,Real-time systems,Rubber,Virtual environments,body ownership,cognitive neuroscientists,human computer interaction,immersive virtual reality,multisensory body illusions,rubber hand illusion,social aspects of automation,virtual body ownership,virtual child body,virtual environments,virtual reality,virtualization,visualization},
month = {jul},
number = {7},
pages = {24--30},
shorttitle = {Computer},
title = {{Transcending the Self in Immersive Virtual Reality}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6861900},
volume = {47},
year = {2014}
}
@inproceedings{DCruz2014,
abstract = {Our vision is that regardless of future variations in the interior of airplane cabins, we can utilize ever-advancing state-of-the-art virtual and mixed reality technologies with the latest research in neuroscience and psychology to achieve high levels of comfort for passengers. Current surveys on passenger's experience during air travel reveal that they are least satisfied with the amount and effectiveness of their personal space, and their ability to work, sleep or rest. Moreover, considering current trends it is likely that the amount of available space is likely to decrease and therefore the passenger's physical comfort during a flight is likely to worsen significantly. Therefore, the main challenge is to enable the passengers to maintain a high level of comfort and satisfaction while being placed in a restricted physical space.},
author = {D'Cruz, Mirabelle and Patel, Harshada and Lewis, Laura and Cobb, Sue and Bues, Matthias and Stefani, Oliver and Grobler, Tredeaux and Helin, Kaj and Viitaniemi, Juhani and Aromaa, Susanna and Frohlich, Bernd and Beck, Stephan and Kunert, Andre and Kulik, Alexander and Karaseitanidis, Ioannis and Psonis, Panagiotis and Frangakis, Nikos and Slater, Mel and Bergstrom, Ilias and Kilteni, Konstantina and Kokkinara, Elena and Mohler, Betty and Leyrer, Markus and Soyka, Florian and Gaia, Enrico and Tedone, Domenico and Olbert, Michael and Cappitelli, Mario},
booktitle = {2014 IEEE Virtual Reality (VR)},
doi = {10.1109/VR.2014.6802104},
file = {:C\:/Users/Nathan/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/D'Cruz et al. - 2014 - Demonstration VR-HYPERSPACE — The innovative use of virtual reality to increase comfort by changing the perceptio.pdf:pdf},
isbn = {978-1-4799-2871-2},
keywords = {Airplanes,Computers,Educational institutions,Neuroscience,Psychology,Shape,VR-HYPERSPACE,Virtual reality,airplane cabin interior,avatars,comfort,future and emerging technology,mixed reality technology,neuroscience,perception,psychology,self-perception,social interaction,virtual reality},
month = {mar},
pages = {167--168},
publisher = {IEEE},
shorttitle = {Virtual Reality (VR), 2014 iEEE},
title = {{Demonstration: VR-HYPERSPACE — The innovative use of virtual reality to increase comfort by changing the perception of self and space}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6802104},
year = {2014}
}
@misc{Bruce2012,
abstract = {In this talk, one of the most oft-asked question of independent game development will be discussed- should I build my own engine for my game, or use an existing middleware? John Edwards (thatgamecompany -Journey) will represent the opinion of building your own and Alexander Bruce (Demruth-Antichamber) represent the middleware-using perspective. Through prepared statements and a moderated debate, the audience will gain a deeper understand of the pros and cons of each. Come to learn, or have your existing preconceptions challenged!},
author = {Bruce, Alexander and Edwards, John and Santiago, Kellee},
booktitle = {Game Developers Conference 2012},
howpublished = {\url{http://www.gdcvault.com/play/1015707/Middleware-vs-Build-Your-Own}},
keywords = {Debate,Video},
mendeley-tags = {Debate,Video},
title = {{Middleware vs Build Your Own - Debate!}},
url = {http://www.gdcvault.com/play/1015707/Middleware-vs-Build-Your-Own},
year = {2012}
}
